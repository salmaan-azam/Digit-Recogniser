{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salmaan-azam/Digit-Recognisor/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx72m2ESyOGD"
      },
      "source": [
        "#MNIST DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtNlfCnF0ENN",
        "outputId": "0e309c95-99a9-4cfe-fd62-f6daebcbe3d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ukVc0AYubgC"
      },
      "source": [
        "# Importing Libraries\n",
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TzRCopqmzQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ce74ea-023f-46f0-8911-5ad4e5fa4b1f"
      },
      "source": [
        "# Downloading training and testing data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nmrq6CTnb-U",
        "outputId": "e2186fb6-0cbd-4f7c-de9e-0da899986759"
      },
      "source": [
        "# Checking dimensions of data\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "TEnm-vSdngYL",
        "outputId": "4c77f525-e7d7-4bbc-91a3-4468a93f5d52"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])\n",
        "plt.title(y_train[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSX9a9mSpABq"
      },
      "source": [
        "# Reshaping traing and testing data\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1 )\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k4L9Slky7t2"
      },
      "source": [
        "# Normalising training and testing data\n",
        "x_train = x_train*1.0/255\n",
        "x_test = x_test*1.0/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tBdfbJWw5yC"
      },
      "source": [
        "# One hot encoding of the outpul labels\n",
        "from  keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
        "y_test= np_utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl1ue2Umxp38",
        "outputId": "13aa6524-0ce5-4b99-b8a4-7136b8bfca63"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GwKXzRcY4JX",
        "outputId": "8c5b0101-0188-475f-d6d0-2485e74d731a"
      },
      "source": [
        "# Checking dimensions of data\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NENqHCdaxq4u"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "from keras import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ud2iDLAzSmb"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUwWxDT8G56O"
      },
      "source": [
        "he = keras.initializers.HeNormal()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcLv4UoM7x4I"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Conv2D(2, (3, 3), kernel_initializer=he, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(4, (3, 3), kernel_initializer=he, activation='relu'))\n",
        "model.add(Conv2D(8, (3, 3), kernel_initializer=he, activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(16, (3, 3), kernel_initializer=he, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), kernel_initializer=he, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_Y9WB8H_ZcI",
        "outputId": "8c3bb999-d359-485a-c4ab-668ad144c05f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 2)         20        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 4)         76        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 8)         296       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                2890      \n",
            "=================================================================\n",
            "Total params: 9,314\n",
            "Trainable params: 9,202\n",
            "Non-trainable params: 112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kun8ex1ytXwv"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.2, min_lr=0.000001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XMpwrsSCxUx"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filename=\"/content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5WaQTbNIlAX"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO32qRCvzYn7"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2CR5aKQQRzq"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE4iYfeiQXzh",
        "outputId": "7c0d0fe5-11a6-4842-f23a-e79734b971b4"
      },
      "source": [
        "history = model.fit(datagen.flow(x_train, y_train), epochs=30, validation_data=(x_test, y_test), callbacks=[checkpoint, lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 36s 11ms/step - loss: 0.7219 - accuracy: 0.7752 - val_loss: 0.0841 - val_accuracy: 0.9706\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.97060, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1687 - accuracy: 0.9475 - val_loss: 0.0479 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.97060 to 0.98410, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1126 - accuracy: 0.9650 - val_loss: 0.0370 - val_accuracy: 0.9882\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.98410 to 0.98820, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0994 - accuracy: 0.9691 - val_loss: 0.0410 - val_accuracy: 0.9876\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.98820\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0873 - accuracy: 0.9737 - val_loss: 0.0308 - val_accuracy: 0.9902\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.98820 to 0.99020, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0795 - accuracy: 0.9752 - val_loss: 0.0403 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.99020\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0763 - accuracy: 0.9769 - val_loss: 0.0336 - val_accuracy: 0.9908\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99020 to 0.99080, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0689 - accuracy: 0.9792 - val_loss: 0.0332 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99080\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0615 - accuracy: 0.9820 - val_loss: 0.0321 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.99080\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0596 - accuracy: 0.9813 - val_loss: 0.0303 - val_accuracy: 0.9909\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99080 to 0.99090, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 0.0235 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99090 to 0.99270, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 0.0222 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99270\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0212 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99270 to 0.99300, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.0215 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.99300 to 0.99380, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0449 - accuracy: 0.9866 - val_loss: 0.0202 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99380\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.0218 - val_accuracy: 0.9931\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99380\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0402 - accuracy: 0.9881 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99380\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0207 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99380\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.0201 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99380\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 0.0199 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99380\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.0200 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.99380 to 0.99390, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.0195 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99390\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.0195 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.99390 to 0.99410, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0196 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99410\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.0196 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99410\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.0196 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99410\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0194 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.99410 to 0.99420, saving model to /content/gdrive/MyDrive/Vision/MNIST/model1.hdf5\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.0195 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99420\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0194 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99420\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0194 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99420\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-06.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js2kHYIMPeen"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD1L67fSPfLv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyLRAwXDp94B"
      },
      "source": [
        "saved_model = keras.models.load_model('/content/gdrive/MyDrive/Vision/MNIST/model1.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYFVqJ3-X-C2",
        "outputId": "f3a52de9-b63b-4f34-9271-1c37ea8fe27b"
      },
      "source": [
        "saved_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01941540464758873, 0.9941999912261963]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}